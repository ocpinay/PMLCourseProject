as.integer(head(hits[,'date']))
mdl <- glm(visits ~ date, poisson, hits)
summary(mdl)
exp(confint(mdl,'date'))
max(hits[,'visits'])
which.max(hits[,'visits'])
hits[704,]
lambda <- mdl$fitted.values[704]
qpois(.95,lambda)
mdl2 <- glm(visits ~ date,poisson, hits,offset=log(visits+1))
mdl2 <- glm(formula = simplystats ~ date, family=poisson, data=hits,offset=log(visits + 1))
qpois(.95,mdl2$fitted.values[704])
library(MASS)
data(shuttle)
str(shuttle)
shuttle$usebin <- as.numeric(shuttle$use == "auto")
fit <- glm(usebin ~ factor(wind) - 1, family = "binomial", data = shuttle)
Coef <- coef(summary(fit))
coef.odds <- exp(c(Coef[1, 1], Coef[2, 1])
;
coef.odds <- exp(c(Coef[1, 1], Coef[2, 1]))
coef.odds[1]/coef.odds[2]
fit2 <- glm(usebin ~ factor(wind) + factor(magn) - 1, family = "binomial",
data = shuttle)
Coef2 <- coef(summary(fit2))
coef2.odds <- exp(c(Coef2[1,1],Coef2[2,1]))
coef2.odds[1]/coef2.odds[2]
fit1 <- glm(I(1 - usebin) ~ factor(wind) - 1, family = "binomial",
data = shuttle)
summary(fit1)$coef
summary(fit)$coef
data("InsectSprays")
mdl4 <- glm(count ~ spray -1, family = "poisson", data = InsectSprays)
summary(mdl4)$coef
coefs <- exp(coef(mdl4))
coefs
coefs[[1]]/coefs[[2]]
mdl5.1 <- glm(count ~ spray, offset = log(count+1), family = poisson, data = InsectSprays)
mdl5.2 <- glm(count ~ spray, offset = log(count+1)+log(10), family = poisson, data = InsectSprays)
summary(mdl5.1)
summary(mdl5.2)
rbind(coef(mdl5.1),coef(mdl5.2))
x <- -5:5
y <- c(5.12, 3.93, 2.67, 1.87, 0.52, 0.08, 0.93, 2.05, 2.54, 3.87, 4.97)
plot(x, y, pch = 21,  cex = 2, col="grey20", bg="cadetblue2")
knots <- 0
splineTerms <- sapply(knots, function(knot) (x > knot) * (x - knot))
xmat <- cbind(1, x, splineTerms)
mdl6 <- lm(y~xmat-1)
yhat<-predict(mdl6)
lines(x, yhat, col = "red", lwd = 2)
summary(mdl6)
sum(coef(mdl6)[2:3])
rm(list=ls())
install.packages("caret")
library(AppliedPredictiveModeling)
suppressMessages(library(caret))
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
suppressMessages(library(caret))
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
testIndex = createDataPartition(diagnosis, p = 0.50, list = FALSE)
training = adData[-testIndex, ]
testing = adData[testIndex, ]
library(AppliedPredictiveModeling)
data(concrete)
suppressMessages(library(caret))
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
par(mfrow = c(2, 1), mar = c(4, 2, 2, 2))
hist(training$Superplasticizer, main = "")
hist(log(training$Superplasticizer + 1), main = "")
suppressMessages(library(caret))
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
predName <- names(training)
(ILpredictor <- predName[substr(predName, 1, 2) == "IL"])
ProcPCA <- preProcess(training[, ILpredictor], method = "pca", thresh = .9)
ProcPCA$numComp
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(Hmisc)
cols <- colnames(training)
subCols <- cols[-length(cols)] #all but CompressiveStrength
plotCols = 2
par(mfrow = c(ceil(length(subCols)/plotCols), plotCols))
res <- sapply(subCols, function(colName){
cut <- cut2(training[,colName])
lab <- paste0("index: col=",colName)
plot(training$CompressiveStrength, pch=19, col=cut, xlab=lab, ylab="CompressiveStrength")
})
install.packages(Hmisc)
install.packages("Hmisc")
library(Hmisc)
cols <- colnames(training)
subCols <- cols[-length(cols)] #all but CompressiveStrength
plotCols = 2
par(mfrow = c(ceil(length(subCols)/plotCols), plotCols))
res <- sapply(subCols, function(colName){
cut <- cut2(training[,colName])
lab <- paste0("index: col=",colName)
plot(training$CompressiveStrength, pch=19, col=cut, xlab=lab, ylab="CompressiveStrength")
})
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
ggplot(data = training, aes(x = Superplasticizer)) + geom_histogram() + theme_bw()
par(mfrow = c(1,2))
hist(training$Superplasticizer, breaks = 50)
hist(log(training$Superplasticizer + 1), breaks = 50)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
predName <- names(training)
(ILpredictor <- predName[substr(predName, 1, 2) == "IL"])
ProcPCA <- preProcess(training[, ILpredictor], method = "pca", thresh = .9)
ProcPCA$numComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainingIL <- training[, c(ILpredictor, "diagnosis")]
testingIL <- testing[, c(ILpredictor, "diagnosis")]
ModelAll <- train(diagnosis ~ ., data = trainingIL, method = "glm")
confusionMatrix(testingIL$diagnosis, predict(ModelAll, testingIL))
createSet <- function(ds){
IL_Colnames = grep("^IL", colnames(ds), value=TRUE,ignore.case=TRUE)
ds[,IL_Colnames]
}
trainingIL <- createSet(training)
testingIL <- createSet(testing)
model_no_pca <- train(training$diagnosis ~ ., trainingIL, method="glm")
predictIL_no_pca <- predict(model_no_pca,testingIL)
result_no_pca <- confusionMatrix(testing$diagnosis, predictIL_no_pca)
result_no_pca$overall["Accuracy"]
install.packages("e1071")
trainingIL <- training[, c(ILpredictor, "diagnosis")]
testingIL <- testing[, c(ILpredictor, "diagnosis")]
ModelAll <- train(diagnosis ~ ., data = trainingIL, method = "glm")
confusionMatrix(testingIL$diagnosis, predict(ModelAll, testingIL))
preProc <- preProcess(training[, ILpredictor], method = "pca", thresh = .8)
trainPC <- predict(preProc, training[, ILpredictor])
ModelPCA <- train(trainingIL$diagnosis ~ ., method = "glm", data = trainPC)
testPC <- predict(preProc, testing[, ILpredictor])
confusionMatrix(testingIL$diagnosis, predict(ModelPCA, testPC))
preProc <- preProcess(training[, ILpredictor], method = "pca", thresh = .8)
> trainPC <- predict(preProc, training[, ILpredictor])
preProc <- preProcess(training[,ILpredictor],method="pca",thresh=.8)
trainPC<-predict(preProc, training[,ILpredictor])
testPC <- predict(preProc,testing[,ILpredictor])
confusionMatrix(testingIL$diagnosis~.,method="glm",data=trainPC)
confusionMatrix(testingIL$diagnosis, predict(ModelPCA, testPC))
ModelPCA <- train(trainingIL$diagnosis ~ ., method = "glm", data = trainPC)
testPC <- predict(preProc, testing[, ILpredictor])
confusionMatrix(testingIL$diagnosis, predict(ModelPCA, testPC))
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
ss <- training[,grep('^IL', x = names(training) )]
preProc <- preProcess(ss, method='pca', thresh=0.8,
outcome=training$diagnosis)
preProc$rotation
preProc
rm(list=ls())
library(AppliedPredictiveModeling)
data(segmentationOriginal)
suppressMessages(library(caret))
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
library(rattle)
install.package("rattle")
install.packages("rattle")
library(rattle)
;
library(rattle)
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages("pgmm")
data(olive)
library(pgmm)
data(olive)
olive = olive[, -1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1], size = dim(SAheart)[1] / 2, replace = F)
trainSA = SAheart[train, ]
testSA = SAheart[-train, ]
missClass = function(values, prediction){sum(((prediction > 0.5) * 1) != values) / length(values)}
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
install.packages("randomForest")
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
subset <- split(segmentationOriginal, segmentationOriginal$Case)
set.seed(125)
modCART <- rpart(Class ~ ., data=subset$Train)
modCART
testA <- segmentationOriginal[0,]
testA[1,c("TotalIntenCh2", "FiberWidthCh1", "PerimStatusCh1")] <- c(23000, 10, 2)
predict(modCART, testA, type="prob")
testB <- segmentationOriginal[0,]
testB[1,c("TotalIntenCh2", "FiberWidthCh1", "VarIntenCh4")] <- c(50000, 10, 100)
predict(modCART, testB, type="prob")
testC <- segmentationOriginal[0,]
testC[1,c("TotalIntenCh2", "FiberWidthCh1", "VarIntenCh4")] <- c(57000, 8, 100)
predict(modCART, testC, type="prob")
testD <- segmentationOriginal[0,]
testD[1,c("FiberWidthCh1", "VarIntenCh4","PerimStatusCh1")] <- c(8, 100, 2)
predict(modCART, testD, type="prob")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
subset <- split(segmentationOriginal, segmentationOriginal$Case)
set.seed(125)
modCART <- rpart(Class ~ ., data=subset$Train)
modCART
testA <- segmentationOriginal[0,]
testA[1,c("TotalIntenCh2", "FiberWidthCh1", "PerimStatusCh1")] <- c(23000, 10, 2)
predict(modCART, testA, type="prob")
testB <- segmentationOriginal[0,]
testB[1,c("TotalIntenCh2", "FiberWidthCh1", "VarIntenCh4")] <- c(50000, 10, 100)
predict(modCART, testB, type="prob")
testC <- segmentationOriginal[0,]
testC[1,c("TotalIntenCh2","FiberWidthCh1","VarIntenCh4")] <- c(57000,8,100)
predict(modCART, testC, type="prob")
testD <- segmentationOriginal[0,]
testD[1,c("FiberWidthCh1","VarIntenCh4","PerimStatusCh1")] <- c(8,100,2)
predict(modCART,testD,type="prob")
fancyRpartPlot(modCART$finalModel)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
head(trainSA)
modelSA <- train(chd ~ age + alcohol+ obesity + tobacco + typea + ldl, method="glm",family="binomial",data=trainSA)
modelSA <- train(chd ~ age + alcohol+ obesity + tobacco + typea + ldl, data=trainSA, method='"glm",family="binomial")
;
;
modelSA <- train(chd ~ age + alcohol+ obesity + tobacco + typea + ldl, data=trainSA, method="glm",family="binomial")
;
;;;;;
?train
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
rm(list=ls())
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
library(caret)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_rf <- train(y ~ ., data = vowel.train, method="rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
mod_rf <- train(y ~ ., data = vowel.train, method="rf")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
sum(pred_gbm[predDF$pred_gbm == predDF$pred_rf] == predDF$y[predDF$pred_gbm == predDF$pred_rf]) / sum(predDF$pred_rf== predDF$pred_gbm)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
library(gbm)
library(lubridate)
install.packages("lubridate")
getwd()
rm(list=ls())
setwd('C:/Users/Liza/Documents/DataScience_PracticalMachineLearning/courseproject')
getwd()
knitr::opts_chunk$set(echo = TRUE)
training<-read.csv('pml-training.csv')
testing<-read.csv('pml-testing.csv')
library(caret)
library(rattle)
library(gridExtra)
notNAs <- function(x) {
as.vector(apply(x, 2, function(x) length(which(!is.na(x)))))
}
colNAs <- notNAs(training)
remCols <- c()
colsTrain <- colnames(training)
nRowsTrain <-nrow(training)
for (cnt in 1:length(colNAs)) {
if (colNAs[cnt] < nRowsTrain) {
remCols <- c(remCols, colsTrain[cnt])
}
}
training <- training[,!(names(training) %in% remCols)]
training <- training [,8:length(colnames(training))]
set.seed(777)
inTrain <-createDataPartition(training$classe,p=0.6)[[1]]
trainingSub <- training[inTrain,]
validationSub <- training[-inTrain,]
set.seed(777)
model1 <- train(classe ~ ., method="rpart",data=trainingSub)
model1 <- train(classe ~ ., method="rpart",data=validationSub)
set.seed(777)
inTrain <-createDataPartition(training$classe,p=0.5)[[1]]
partition1 <- training[inTrain,]
partition2 <- training[-inTrain,]
set.seed(777)
inTrain2 <-createDataPartition(partition1$classe,p=0.5)[[1]]
smallTrain1 <- partition1[inTrain2,]
smallTrain2 <- partition1[-inTrain2,]
set.seed(777)
inTrain3 <-createDataPartition(partition2$classe,p=0.5)[[1]]
smallTrain3 <- partition2[inTrain3,]
smallTest <- partition2[-inTrain3,]
set.seed(777)
model1 <- train(classe ~ ., method="rpart",data=smallTrain1)
rm(list=ls())
training<-read.csv('pml-training.csv',na.strings=c("NA",""),header=TRUE)
testing<-read.csv('pml-testing.csv',na.strings=c("NA",""),header=TRUE)
library(caret)
library(rattle)
library(gridExtra)
notNAs <- function(x) {
as.vector(apply(x, 2, function(x) length(which(!is.na(x)))))
}
colNAs <- notNAs(training)
remCols <- c()
colsTrain <- colnames(training)
nRowsTrain <-nrow(training)
for (cnt in 1:length(colNAs)) {
if (colNAs[cnt] < nRowsTrain) {
remCols <- c(remCols, colsTrain[cnt])
}
}
training <- training[,!(names(training) %in% remCols)]
training <- training [,8:length(colnames(training))]
set.seed(777)
inTrain = createDataPartition(training$classe, p = .60)[[1]]
trainingSub = training[inTrain,]
validationSub = training[-inTrain,]
set.seed(777)
model1 <- train(classe ~ ., method="rpart",data=trainingSub)
print(model1$finalModel)
validationPredict=predict(modFit,validationSub)
validationPredict=predict(model1,validationSub)
confusionMatrix(validationSub$classe,validationPredict)
set.seed(777)
model2 <- train(classe ~ ., method="rf",trControl=trainControl(method = "cv", number = 5), data=trainingSub)
set.seed(777)
model2 <- train(classe ~ ., method="rf",trControl=trainControl(method = "cv", number = 3), data=trainingSub)
print(model2)
varImp(model2)
validationPredict2<-predict(model2,validationSub)
confusionMatrix(validationSub$classe,validationPredict2)
trainingPredict <- predict(model2,trainingSub)
confusionMatrix(trainingSub$classe,trainingPredict)
testingPredict <- predict(model2,testing)
confusionMatrix(testing$classe,testing)
testing <- testing[,!(names(testing) %in% remCols)]
testing <- testing[,8:length(colnames(testing))]
testingPredict <- predict(model2,testing)
confusionMatrix(testing$classe,testing)
confusionMatrix(testing$classe,testingPredict)
head(testing)
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
training<-read.csv('pml-training.csv',na.strings=c("NA",""),header=TRUE)
testing<-read.csv('pml-testing.csv',na.strings=c("NA",""),header=TRUE)
library(caret)
library(rattle)
library(gridExtra)
notNAs <- function(x) {
as.vector(apply(x, 2, function(x) length(which(!is.na(x)))))
}
colNAs <- notNAs(training)
remCols <- c()
colsTrain <- colnames(training)
nRowsTrain <-nrow(training)
for (cnt in 1:length(colNAs)) {
if (colNAs[cnt] < nRowsTrain) {
remCols <- c(remCols, colsTrain[cnt])
}
}
training <- training[,!(names(training) %in% remCols)]
testing <- testing[,!(names(testing) %in% remCols)]
training <- training [,8:length(colnames(training))]
testing <- testing[,8:length(colnames(testing))]
set.seed(777)
inTrain = createDataPartition(training$classe, p = .60)[[1]]
trainingSub = training[inTrain,]
validationSub = training[-inTrain,]
set.seed(777)
model1 <- train(classe ~ ., method="rpart",data=trainingSub)
validationPredict=predict(model1,validationSub)
confusionMatrix(validationSub$classe,validationPredict)
set.seed(777)
model2 <- train(classe ~ ., method="rf",trControl=trainControl(method = "cv", number = 3), data=trainingSub)
print(model2)
validationPredict2<-predict(model2,validationSub)
confusionMatrix(validationSub$classe,validationPredict2)
trainingPredict <- predict(model2,trainingSub)
confusionMatrix(trainingSub$classe,trainingPredict)
testingPredict <- predict(model2,testing)
confusionMatrix(testing$classe,testingPredict)
testing2<-read.csv('pml-testing.csv',na.strings=c("NA",""),header=TRUE)
colnames(testing2)
testingPredict <- predict(model2,testing,type="response",predict.all=FALSE)
testingPredict <- predict(model2,testing,type="raw",predict.all=FALSE)
print(testingPredict)
model3 <- train(classe ~ ., method="rf",trControl=trainControl(method = "cv", number = 4), data=trainingSub)
print(model3)
validationPredict3<-predict(model3,validationSub)
confusionMatrix(validationSub$classe,validationPredict3)
